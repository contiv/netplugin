# -*- mode: ruby -*-
# vi: set ft=ruby :

require File.join(File.dirname(__FILE__), "..", "vagrant_version_check")

require 'fileutils'

# netplugin_synced_gopath="/opt/golang"
gopath_folder="/opt/gopath"

cluster_ip_nodes = ""

provision_common_once = <<SCRIPT
## setup the environment file. Export the env-vars passed as args to 'vagrant up'
echo Args passed: [[ $@ ]]
echo -n "$1" > /etc/hostname
hostname -F /etc/hostname

echo 'export GOPATH=#{gopath_folder}' > /etc/profile.d/envvar.sh
echo 'export GOBIN=$GOPATH/bin' >> /etc/profile.d/envvar.sh
echo 'export GOSRC=$GOPATH/src' >> /etc/profile.d/envvar.sh
echo 'export PATH=$PATH:/usr/local/go/bin:$GOBIN' >> /etc/profile.d/envvar.sh
echo "export http_proxy='$4'" >> /etc/profile.d/envvar.sh
echo "export https_proxy='$5'" >> /etc/profile.d/envvar.sh
echo "export NIGHTLY_RELEASE=$6" >> /etc/profile.d/envvar.sh
echo "export no_proxy=$3,127.0.0.1,localhost,netmaster" >> /etc/profile.d/envvar.sh
echo "export CLUSTER_NODE_IPS=$3" >> /etc/profile.d/envvar.sh
echo "export CONTIV_CLUSTER_STORE_DRIVER=$7" >> /etc/profile.d/envvar.sh
echo "export CONTIV_CLUSTER_STORE_URL=$8" >> /etc/profile.d/envvar.sh
source /etc/profile.d/envvar.sh

if [[ $# -gt 10 ]] && [[ ${11} != "" ]]; then
    shift 10
    echo "export $@" >> /etc/profile.d/envvar.sh
fi

# Change ownership for gopath folder
chown -R vagrant #{gopath_folder}


# Install specific docker version if required
if [[ $9 != "" ]]; then
    echo "Installing docker version " $9
    if [[ ${10} == "ubuntu" ]]; then
        curl https://get.docker.com | sed s/docker-engine/docker-engine=$9-0~vivid/ | bash
    else
        # cleanup openstack-kilo repo if required
        yum-config-manager --disable openstack-kilo
        curl https://get.docker.com | sed s/docker-engine/docker-engine-$9/ | bash
    fi
fi
# setup docker cluster store
if [[ $7 == "consul" ]]
then
    cp #{gopath_folder}/src/github.com/contiv/netplugin/scripts/docker.service.consul /lib/systemd/system/docker.service
else
    cp #{gopath_folder}/src/github.com/contiv/netplugin/scripts/docker.service /lib/systemd/system/docker.service
fi
# setup docker remote api
cp #{gopath_folder}/src/github.com/contiv/netplugin/scripts/docker-tcp.socket /etc/systemd/system/docker-tcp.socket
systemctl enable docker-tcp.socket
mkdir -p /etc/systemd/system/docker.service.d
echo "[Service]" | sudo tee -a /etc/systemd/system/docker.service.d/http-proxy.conf
echo "Environment=\\\"no_proxy=$CLUSTER_NODE_IPS,127.0.0.1,localhost,netmaster\\\" \\\"http_proxy=$http_proxy\\\" \\\"https_proxy=$https_proxy\\\"" | sudo tee -a /etc/systemd/system/docker.service.d/http-proxy.conf
sudo systemctl daemon-reload
sudo systemctl stop docker
rm -rf /var/lib/docker/*
sudo gpasswd -a vagrant docker
systemctl start docker-tcp.socket
sudo systemctl restart docker

# remove duplicate docker key
rm /etc/docker/key.json
service docker restart || exit 1
SCRIPT

provision_common_always = <<SCRIPT
/sbin/ip addr flush dev eth1 && /sbin/ip addr add "$2/24" dev eth1
/sbin/ip link set eth1 up
/sbin/ip link set eth2 up
/sbin/ifconfig eth1

# Drop cache to workaround vboxsf problem
echo 3 > /proc/sys/vm/drop_caches

# Enable ovs mgmt port
(ovs-vsctl set-manager tcp:127.0.0.1:6640 && \
 ovs-vsctl set-manager ptcp:6640) || exit 1

SCRIPT

build_netplugin = <<BUILD_SCRIPT
echo "============ build ================= "
cd /opt/gopath/src/github.com/contiv/netplugin && make host-build
BUILD_SCRIPT

VAGRANTFILE_API_VERSION = "2"
ENV['VAGRANT_NO_PARALLEL'] = 'yes'
ENV['CONTIV_NODE_OS'] = "ubuntu"
Vagrant.configure(VAGRANTFILE_API_VERSION) do |config|
    config.vm.box_version = "0.7.0"
    if ENV['CONTIV_NODE_OS'] && ENV['CONTIV_NODE_OS'] == "ubuntu" then
        config.vm.box = "contiv/mesos-ubuntu1504"
    else
        config.vm.box = "contiv/mesos-ubuntu1504"
    end
    config.vm.provider 'virtualbox' do |v|
        v.linked_clone = true if Vagrant::VERSION >= "1.8"
    end

    num_nodes = 2
    if ENV['CONTIV_NODES'] && ENV['CONTIV_NODES'] != "" then
        num_nodes = ENV['CONTIV_NODES'].to_i
    end
    base_ip = "192.168.2."
    if ENV['CONTIV_IP_PREFIX'] && ENV['CONTIV_IP_PREFIX'] != "" then
        base_ip = ENV['CONTIV_IP_PREFIX']
    end
    node_ips = num_nodes.times.collect { |n| base_ip + "#{n+10}" }
    cluster_ip_nodes = node_ips.join(",")

    node_names = num_nodes.times.collect { |n| "mesos-node#{n+1}" }
    node_peers = []

    num_nodes.times do |n|
        node_name = node_names[n]
        node_addr = node_ips[n]
        node_peers += ["#{node_name}=http://#{node_addr}:2380,#{node_name}=http://#{node_addr}:7001"]
        consul_join_flag = if n > 0 then "-join #{node_ips[0]}" else "" end
        consul_bootstrap_flag = "-bootstrap-expect=3"
        if num_nodes < 3 then
            if n == 0 then
                consul_bootstrap_flag = "-bootstrap"
            else
                consul_bootstrap_flag = ""
            end
        end
        config.vm.define node_name do |node|

            # node.vm.hostname = node_name
            # create an interface for etcd cluster
            node.vm.network :private_network, ip: node_addr, auto_config: false
            # create an interface for bridged network
            node.vm.network :private_network, ip: "0.0.0.0", virtualbox__intnet: "true", auto_config: false
            node.vm.provider "virtualbox" do |v|
                # make all nics 'virtio' to take benefit of builtin vlan tag
                # support, which otherwise needs to be enabled in Intel drivers,
                # which are used by default by virtualbox
                v.customize ['modifyvm', :id, '--nictype1', 'virtio']
                v.customize ['modifyvm', :id, '--nictype2', 'virtio']
                v.customize ['modifyvm', :id, '--nictype3', 'virtio']
                v.customize ['modifyvm', :id, '--nicpromisc2', 'allow-all']
                v.customize ['modifyvm', :id, '--nicpromisc3', 'allow-all']
                v.customize ['modifyvm', :id, '--paravirtprovider', "kvm"]
            end

            # mount the host directories
            node.vm.synced_folder "../../bin", File.join(gopath_folder, "bin")
            if ENV["GOPATH"] && ENV['GOPATH'] != ""
              node.vm.synced_folder "../../../../../", File.join(gopath_folder, "src"), rsync: true
            else
              node.vm.synced_folder "./../../", File.join(gopath_folder, "src/github.com/contiv/netplugin"), rsync: true
            end

            node.vm.provision "shell" do |s|
                s.inline = "echo '#{node_ips[0]} netmaster' >> /etc/hosts; echo '#{node_ips[1]} netmaster' >> /etc/hosts;	echo '#{node_addr} #{node_name}' >> /etc/hosts"
            end
            node.vm.provision "shell" do |s|
                s.inline = provision_common_once
                s.args = [node_name, node_addr, cluster_ip_nodes, ENV["http_proxy"] || "", ENV["https_proxy"] || "", ENV["NIGHTLY_RELEASE"] || "", \
                        ENV["CONTIV_CLUSTER_STORE_DRIVER"] || "etcd", ENV["CONTIV_CLUSTER_STORE_URL"] || "http://localhost:2379", \
                        ENV["CONTIV_DOCKER_VERSION"] || "", ENV['CONTIV_NODE_OS'] || "", *ENV['CONTIV_ENV']]
            end
            node.vm.provision "shell", run: "always" do |s|
                s.inline = provision_common_always
                s.args = [node_name, node_addr]
            end

provision_node = <<SCRIPT
## start etcd with generated config
set -x
NODEID=$1
NODENAME=$2
NODEADDR=$3
MASTERADDR=$4

(nohup etcd --name #{node_name} --data-dir /tmp/etcd \
 -heartbeat-interval=100 -election-timeout=5000 \
 --listen-client-urls http://0.0.0.0:2379,http://0.0.0.0:4001 \
 --advertise-client-urls http://#{node_addr}:2379,http://#{node_addr}:4001 \
 --initial-advertise-peer-urls http://#{node_addr}:2380,http://#{node_addr}:7001 \
 --listen-peer-urls http://#{node_addr}:2380 \
 --initial-cluster #{node_peers.join(",")} --initial-cluster-state new \
  0<&- &>/tmp/etcd.log &) || exit 1
sleep 2

## start consul
(nohup consul agent -server #{consul_join_flag} #{consul_bootstrap_flag} \
 -bind=#{node_addr} -data-dir /opt/consul 0<&- &>/tmp/consul.log &) || exit 1

# setup mesos & marathon
if [[ "$NODEID" == "0" ]]; then
   echo "configure mesos master node $NODEID, $NODENAME, $NODEADDR"
   service zookeeper restart
   nohup /usr/sbin/mesos-master  --ip=$NODEADDR --work_dir=/tmp/mesos_master > /tmp/mesos-master.log 2>&1 &
   nohup /home/vagrant/marathon/bin/start  --master $NODEADDR:5050 --zk zk://localhost:2181/marathon  \
       --task_launch_timeout 300000 > /tmp/marathon.log 2>&1 &
   docker run -itd --net host contiv/contiv-ui
fi

echo "configure mesos slave node $NODEID, $NODENAME, $NODEADDR"
mkdir -p /var/lib/mesos/cni/plugins/
mkdir -p /var/lib/mesos/cni/config/
mkdir -p /var/lib/mesos/cni/logs/
cat >  /var/lib/mesos/cni/config/contiv.cfg <<EOF
{
   "name": "netcontiv",
   "type": "netcontiv"
}
EOF
cp /opt/gopath/bin/netcontiv  /var/lib/mesos/cni/plugins/
nohup /usr/sbin/mesos-slave  --ip=$NODEADDR --work_dir=/var/lib/mesos/ \
      --master=$MASTERADDR:5050 --containerizers=mesos --executor_registration_timeout=5mins \
      --network_cni_config_dir=/var/lib/mesos/cni/config/ \
      --network_cni_plugins_dir=/var/lib/mesos/cni/plugins/ \
      --isolation=filesystem/linux,docker/runtime \
      --http_command_executor                     \
      --hostname=$NODENAME                        \
      --logging_level=INFO --log_dir=/var/lib/mesos/cni/logs/ \
      --image_providers=docker  > /tmp/mesos-slave.log 2>&1 &
sleep 2

SCRIPT
            if n == 0 then
                node.vm.provision "shell", run: "always" do |s|
                    s.inline = build_netplugin
                    s.privileged = false
		end
            end

            node.vm.provision "shell", run: "always" do |s|
                s.inline = provision_node
                s.args = [n, node_name, node_addr, node_ips[0]]
            end


        end
    end
end
